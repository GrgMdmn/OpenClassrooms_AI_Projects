# Projet de Traitement Big Data sur le Cloud - Fruits!

## ğŸ“‹ Contexte du projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre d'une mission de consulting pour **Fruits!**, une jeune start-up AgriTech qui dÃ©veloppe des solutions innovantes pour la rÃ©colte des fruits. L'entreprise souhaite prÃ©server la biodiversitÃ© des fruits en permettant des traitements spÃ©cifiques pour chaque espÃ¨ce grÃ¢ce au dÃ©veloppement de robots cueilleurs intelligents.

## ğŸ¯ Objectifs

ComplÃ©ter une chaÃ®ne de traitement d'extraction de features dans un environnement Big Data sur le cloud AWS :

1. **Reprise des travaux** : S'approprier le notebook incomplet d'un alternant prÃ©cÃ©dent
2. **ComplÃ©tion de la pipeline** : ImplÃ©menter les parties manquantes (broadcast des poids, PCA distribuÃ©e)
3. **Mise en production** : DÃ©ployer la solution sur un cluster AWS EMR conforme au RGPD
4. **Optimisation des coÃ»ts** : Maintenir les coÃ»ts d'exÃ©cution sous 10â‚¬

L'objectif Ã  long terme est de mettre en place un moteur de classification des images de fruits pour une application mobile de sensibilisation du grand public.

## ğŸ“Š DonnÃ©es

Le jeu de donnÃ©es utilisÃ© est **Fruits-360**, disponible sur Kaggle :
- **147 691 images** de fruits de diffÃ©rentes variÃ©tÃ©s
- Format : 100x100 pixels, couleur
- Jeu de test spÃ©cifique : 103 images de fruits multiples
- **âš ï¸ Note importante** : Le jeu de donnÃ©es n'est pas inclus dans ce dÃ©pÃ´t en raison de sa taille
- **URL** : https://www.kaggle.com/moltean/fruits

## ğŸ“ Structure du projet

```
â”œâ”€â”€ P11_01_notebook.ipynb
â”œâ”€â”€ P11_02_images/
â”‚   â”œâ”€â”€ Results_PCA/                    # RÃ©sultats PCA au format Parquet
â”‚   â”‚   â”œâ”€â”€ part-00000-*.parquet
â”‚   â”‚   â”œâ”€â”€ part-00001-*.parquet
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ test-multiple-fruits/           # Images de test (103 images)
â”‚       â”œâ”€â”€ apple.jpg
â”‚       â”œâ”€â”€ apples1.jpg
â”‚       â””â”€â”€ ...
â””â”€â”€ P11_03_prÃ©sentation.pdf
```

### 1. `P11_01_notebook.ipynb`

**Notebook principal de traitement Big Data PySpark**

Ce notebook contient la chaÃ®ne complÃ¨te de traitement :

- **Initialisation** : Configuration de la SparkSession et connexion Ã  S3
- **Chargement des donnÃ©es** : Lecture des images depuis S3 en format binaire
- **Transfer Learning** : Extraction de features via MobileNetV2 prÃ©-entraÃ®nÃ© sur ImageNet
  - Suppression de la couche de classification finale
  - Extraction de vecteurs de 1280 dimensions
  - Broadcast des poids du modÃ¨le aux workers (ajout critique)
- **RÃ©duction de dimensionnalitÃ©** : PCA distribuÃ©e avec Spark ML
  - RÃ©duction de 1280 â†’ 70 dimensions
  - Conservation de 99,94% de la variance
  - Optimisation du stockage et des performances
- **Export des rÃ©sultats** : Sauvegarde au format Parquet sur S3

**Optimisations clÃ©s implÃ©mentÃ©es** :
- Pandas UDF Scalar Iterator pour traitement par batch
- Broadcast des poids du modÃ¨le pour Ã©viter les chargements rÃ©pÃ©titifs
- PCA distribuÃ©e avec calcul parallÃ©lisÃ© sur le cluster

### 2. `P11_02_images/`

**Dossier des images et rÃ©sultats**

- **Results_PCA/** : RÃ©sultats de la rÃ©duction de dimensionnalitÃ© stockÃ©s au format Parquet distribuÃ© (20 fichiers)
- **test-multiple-fruits/** : 103 images de test variÃ©es utilisÃ©es pour valider la pipeline

### 3. `P11_03_prÃ©sentation.pdf`

**PrÃ©sentation des rÃ©sultats**

Cette prÃ©sentation synthÃ©tise :
- Le contexte et les enjeux du projet
- L'architecture cloud mise en place (AWS EMR, S3, EC2)
- La configuration du cluster et les optimisations Spark
- Le pipeline algorithmique complet
- Les rÃ©sultats techniques obtenus
- Les perspectives d'amÃ©lioration et de dÃ©ploiement

## ğŸ› ï¸ Technologies utilisÃ©es

### Cloud & Infrastructure
- **AWS EMR** : Cluster de calcul distribuÃ© (Spark, Hadoop)
- **AWS S3** : Stockage des donnÃ©es et rÃ©sultats
- **AWS EC2** : Instances m5.xlarge (1 Master + 2 Workers)
- **RÃ©gion EU-West-3** (Paris) : ConformitÃ© RGPD

### Big Data & Traitement
- **PySpark** : Framework de calcul distribuÃ©
- **Hadoop** : SystÃ¨me de fichiers distribuÃ©
- **Spark ML** : BibliothÃ¨que de Machine Learning distribuÃ©e

### Machine Learning
- **TensorFlow** : Framework de deep learning
- **MobileNetV2** : ModÃ¨le de transfer learning prÃ©-entraÃ®nÃ© sur ImageNet
- **PCA** : Algorithme de rÃ©duction de dimensionnalitÃ©

### Outils de dÃ©veloppement
- **JupyterHub** : Environnement de dÃ©veloppement sur le cluster
- **SSH Tunneling** : AccÃ¨s sÃ©curisÃ© au cluster
- **Python 3** : Langage de programmation

## ğŸ“ˆ Architecture technique

### Configuration du Cluster EMR

**Instances** :
- 1 nÅ“ud Master (driver Spark) - m5.xlarge
- 2 nÅ“uds Workers (executors Spark) - m5.xlarge
- RÃ©gion : eu-west-3 (Paris)

**Logiciels installÃ©s** :
- Hadoop 3.2.1
- Spark 3.1.2
- JupyterHub 1.4.1
- TensorFlow 2.4.1

**Bootstrap** : Installation automatique des packages Python
```bash
sudo python3 -m pip install numpy pandas pillow pyarrow fsspec s3fs
```

### AccÃ¨s SÃ©curisÃ©

**Tunneling SSH avec Port Forwarding** :
```bash
ssh -i ./emr-keypair.pem -L 8890:localhost:8890 -L 9443:localhost:9443 hadoop@[IP-EMR]
```
- Port 9443 : JupyterHub (dÃ©veloppement)
- Port 8890 : Interface monitoring Spark

**Avantages** :
- Connexion chiffrÃ©e de bout en bout
- Pas de proxy externe nÃ©cessaire
- ContrÃ´le prÃ©cis des accÃ¨s

### Pipeline de Traitement

1. **Chargement des images** : Format binaire depuis S3, extraction des labels depuis les chemins
2. **Transfer Learning** : MobileNetV2 â†’ features 1280 dimensions
   - Broadcast des poids pour distribution efficace
   - Pandas UDF Scalar Iterator pour traitement par batch
3. **PCA DistribuÃ©e** : RÃ©duction 1280 â†’ 70 dimensions
   - Calcul distribuÃ© de la matrice de covariance
   - Extraction des composantes principales
   - Transformation des features
4. **Export** : Sauvegarde au format Parquet sur S3

## ğŸ“ MÃ©thodologie

1. **ComprÃ©hension** : Analyse du notebook existant et identification des manques
2. **DÃ©veloppement local** : Tests et validation sur Ã©chantillon rÃ©duit
3. **Migration cloud** : DÃ©ploiement sur cluster EMR
4. **Optimisation** : Ajout du broadcast et de la PCA distribuÃ©e
5. **Validation** : Tests sur 103 images, vÃ©rification de la scalabilitÃ©

## ğŸ’° Gestion des coÃ»ts

**Objectif** : < 10â‚¬ pour la validation

**StratÃ©gies d'optimisation** :
- Utilisation d'un cluster modeste (1 Master + 2 Workers)
- Instances m5.xlarge (compromis performance/coÃ»t)
- Tests sur Ã©chantillon rÃ©duit avant passage Ã  l'Ã©chelle
- ArrÃªt du cluster aprÃ¨s utilisation
- Serveur local pour dÃ©veloppement et tests

**RÃ©sultat** : CoÃ»t de validation < 5â‚¬ (moins d'1h de cluster)

## ğŸ¯ RÃ©sultats

### Techniques

- âœ… RÃ©duction de dimensionnalitÃ© : 1280 â†’ 70 dimensions
- âœ… Variance conservÃ©e : **99,94%**
- âœ… Facteur de compression : **x4,1**
- âœ… Pipeline complÃ¨te et fonctionnelle
- âœ… Architecture scalable validÃ©e

### ConformitÃ©

- âœ… **RGPD** : RÃ©gion EU-West-3 (Paris)
- âœ… **SÃ©curitÃ©** : AccÃ¨s SSH, tunneling sÃ©curisÃ©
- âœ… **CoÃ»ts** : < 10â‚¬ pour la validation

### FonctionnalitÃ©s implÃ©mentÃ©es

- âœ… Broadcast des poids MobileNetV2 (manquant dans version initiale)
- âœ… PCA distribuÃ©e avec Spark ML (manquant dans version initiale)
- âœ… Optimisation mÃ©moire avec Pandas UDF Scalar Iterator
- âœ… Export des rÃ©sultats au format Parquet

## ğŸš€ Perspectives

### Court terme

**Optimisation de la PCA** :
- 70 composantes valables pour 103 images de test
- Avec dataset complet (~150k images), ajuster le nombre de composantes k
- Tester diffÃ©rentes valeurs pour optimiser variance/dimensions

**Classification finale** :
- EntraÃ®ner un modÃ¨le de classification sur les features PCA
- Ã‰valuer les performances sur le jeu de test
- Fine-tuning du nombre de composantes

### Moyen terme

**DÃ©ploiement production** :
- IntÃ©gration du modÃ¨le dans l'application mobile
- Pipeline CI/CD automatisÃ©e
- Monitoring des performances en temps rÃ©el
- Gestion des versions du modÃ¨le

### Long terme

**Extensions futures** :
- Utilisation de l'application comme MVP marketing et technique
- Collecte de nouvelles donnÃ©es terrain
- AmÃ©lioration continue du modÃ¨le
- IntÃ©gration avec les robots cueilleurs intelligents

## ğŸ“ CompÃ©tences dÃ©veloppÃ©es

- Architecture Big Data sur le cloud (AWS EMR, S3, EC2)
- Traitement distribuÃ© avec PySpark
- Transfer Learning et extraction de features
- RÃ©duction de dimensionnalitÃ© Ã  grande Ã©chelle
- Optimisation des performances Spark
- Gestion des coÃ»ts cloud
- ConformitÃ© RGPD pour le stockage de donnÃ©es

## ğŸ‘¤ Auteur

**GrÃ©goire Mureau**  
Date de rÃ©alisation : Octobre 2025

---

*Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du parcours AI Engineer*

# âœ¨ Analyse de sentiments et dÃ©ploiement MLOps : retour dâ€™expÃ©rience complet

Dans le cadre du projet *Air Paradis*, nous avons mis en Å“uvre une chaÃ®ne complÃ¨te dâ€™analyse de sentiments Ã  partir de tweets, depuis la modÃ©lisation jusquâ€™au dÃ©ploiement MLOps. Ce billet de blog revient sur lâ€™ensemble des Ã©tapes rÃ©alisÃ©es, les choix mÃ©thodologiques, la comparaison des modÃ¨les et la mise en production dâ€™une API. ğŸ§ ğŸ”§

---

## ğŸ” Trois approches de modÃ©lisation supervisÃ©e

Nous avons testÃ© trois approches complÃ©mentaires pour prÃ©dire le sentiment dâ€™un tweet. Chacune sâ€™appuie sur un type de reprÃ©sentation des textes et un algorithme diffÃ©rent :

### 1. ğŸ§± Approche simple : Bag-of-Words (BoW) + modÃ¨les de machine learning

Cette approche utilise des vecteurs BoW ou BoW + TF-IDF, qui capturent la frÃ©quence des mots dans les tweets. On fait le choix dâ€™Ã©viter des techniques non supervisÃ©es comme **LDA**, car elles sont plus adaptÃ©es Ã  des tÃ¢ches de topic modeling et non de classification de sentiments (binaire qui plus est).

â¡ï¸ **ModÃ¨les testÃ©s :**  
- RÃ©gression Logistique  
- Naive Bayes  
- SVM  
- Random Forest  

Ces modÃ¨les ont Ã©tÃ© entraÃ®nÃ©s avec **GridSearchCV**, en optimisant la **prÃ©cision (`precision` et non `accuracy`)**, notre KPI principal.

ğŸ“¸ *[InsÃ©rer ici une capture dâ€™Ã©cran MLFlow avec les scores des modÃ¨les simples]*

---

### 2. ğŸ”¥ Approche avancÃ©e : Word Embeddings (Word2Vec & GloVe 300d) + LSTM

On reprÃ©sente les mots non plus comme des frÃ©quences mais comme des vecteurs denses, porteurs de signification.  
Nous avons utilisÃ© :
- **Word2Vec**, entraÃ®nÃ© sur un grand corpus (skip-gram),
- **GloVe 300d**, embeddings prÃ©calculÃ©s par Stanford.

Ces reprÃ©sentations sont **statistiquement proches** entre mots au sens sÃ©mantique.  
Elles **ne tiennent cependant pas compte du contexte exact dans la phrase** :  
> Â« banque Â» aura le mÃªme vecteur que ce soit pour une banque d'argent ou une banque de donnÃ©es.

La classification se fait via un **LSTM** (Long Short-Term Memory), une architecture de **deep learning supervisÃ©e** adaptÃ©e aux sÃ©quences de mots.

ğŸ§  **Le modÃ¨le retenu pour le dÃ©ploiement est sÃ©lectionnÃ© automatiquement dans MLflow parmi les deux (Word2Vec ou GloVe), en fonction de celui qui obtient la prÃ©cision maximale.**  
Cela permet dâ€™avoir un compromis optimal entre lÃ©gÃ¨retÃ© (CPU-friendly) et performance.

ğŸ“¸ *[InsÃ©rer ici une capture dâ€™Ã©cran du graphe de prÃ©cision sur validation pour GloVe+LSTM]*

---

### 3. ğŸ¤– BERT : Bidirectional Encoder Representations from Transformers

BERT est un modÃ¨le de langage avancÃ©, prÃ©entraÃ®nÃ© par Google, capable de **comprendre le contexte bidirectionnel** dâ€™un mot dans une phrase. Contrairement aux word embeddings classiques, BERT :
- **encode dynamiquement les mots** selon leur contexte dâ€™usage (ex. Â« banque Â» nâ€™aura pas le mÃªme vecteur selon la phrase),
- est entraÃ®nÃ© par **masked language modeling** et **next sentence prediction**, puis fine-tunÃ© pour la classification supervisÃ©e.

Cependant, il a ses **limites** :
> âš ï¸ BERT **ne comprend pas lâ€™ironie, le sarcasme ou les rÃ©fÃ©rences culturelles implicites**.  
> Il reste un modÃ¨le basÃ© sur des cooccurrences statistiques, sans connaissance du monde ou intentionnalitÃ©.  
> Or, **Twitter est un terrain propice au second degrÃ©**, aux dÃ©tournements ou aux trolls : ce type de contenu reste un **vÃ©ritable dÃ©fi pour les modÃ¨les classiques de NLP.**

ğŸ“¸ *[InsÃ©rer ici un graphique montrant la prÃ©cision de BERT sur le jeu de validation]*

---

## ğŸ“ Choix du KPI : pourquoi la prÃ©cision (precision) ?

Nous avons fait le choix de nous focaliser sur la **prÃ©cision** plutÃ´t que lâ€™**accuracy** :

> ğŸ¯ **Objectif mÃ©tier :** Ã©viter de **classer un tweet comme positif alors quâ€™il est nÃ©gatif**, car cela pourrait induire une mauvaise communication ou une mauvaise interprÃ©tation dans un contexte sensible.

### Pour chaque type de modÃ¨le :
- ModÃ¨les classiques â†’ optimisation via **GridSearchCV sur la prÃ©cision**  
- ModÃ¨les DL â†’ **EarlyStopping sur val_loss**, mais sÃ©lection du **meilleur modÃ¨le selon la prÃ©cision** sur lâ€™ensemble de validation.

---

## âš™ï¸ Mise en place de lâ€™environnement MLOps maison

Nous avons choisi une **infrastructure MLOps souveraine et autonome** pour orchestrer les expÃ©rimentations.

### ğŸ  Serveur personnel (NAS) + OpenMediaVault
Nous avons dÃ©ployÃ© MLFlow sur un NAS personnel tournant sous **OpenMediaVault** (basÃ© sur Debian).

### ğŸ“¦ Artefacts dans MinIO
Les modÃ¨les, mÃ©triques, visualisations et paramÃ¨tres sont stockÃ©s dans **MinIO**, un systÃ¨me compatible S3.  
â¡ï¸ MinIO est open-source, lÃ©ger, et permet une **gestion souveraine des artefacts**, contrairement Ã  AWS S3.

> Les notebooks (en particulier ceux entraÃ®nÃ©s sur Google Colab, pour bÃ©nÃ©ficier de GPU) envoient automatiquement leurs logs vers MLFlow et leurs artefacts vers MinIO, via des **variables dâ€™environnement** pour sÃ©curiser les identifiants.

ğŸ“¸ *[InsÃ©rer ici une capture du dashboard MLFlow]*

---

## ğŸ§ª IntÃ©gration continue, tests, versioning

Une fois les modÃ¨les validÃ©s, nous avons implÃ©mentÃ© toute la chaÃ®ne MLOps pour le dÃ©ploiement API :

### âœ… Tests automatisÃ©s
- **Tests unitaires** pour valider le prÃ©traitement des tweets, les prÃ©dictions et la gestion des erreurs.
- Ces tests sont intÃ©grÃ©s dans **GitHub Actions**, et **empÃªchent tout dÃ©ploiement Docker si les tests Ã©chouent**.

### ğŸ³ Conteneurisation & CI/CD
- Lâ€™API est packagÃ©e via **Docker**, puis poussÃ©e automatiquement sur **DockerHub** en cas de succÃ¨s.
- Cela permet un dÃ©ploiement cohÃ©rent et rapide sur nâ€™importe quelle plateforme.

---

## ğŸš€ DÃ©ploiement de lâ€™API FastAPI

### ğŸ› ï¸ Backend : FastAPI
- Fournit un endpoint `/predict`, avec chargement dynamique du modÃ¨le via MLFlow et rÃ©cupÃ©ration des embeddings (BoW, GloVe ou Word2Vec) selon le tag `embedding_type`.

ğŸ§  Le modÃ¨le de type Word Embeddings + LSTM avec la **meilleure prÃ©cision** est automatiquement rÃ©cupÃ©rÃ© depuis le *Model Registry* MLFlow.

### ğŸ’» Frontend local : Streamlit
- Sert dâ€™**interface utilisateur** pour tester les prÃ©dictions en local, simuler des requÃªtes API et visualiser les rÃ©sultats.  
- Câ€™est aussi un outil utile pour les dÃ©monstrations ou le debug.

ğŸ“¸ *[InsÃ©rer capture Streamlit en action]*

---

### ğŸŒ ProblÃ¨me matÃ©riel sur le NAS
Le NAS utilise un processeur **Intel N100**, thÃ©oriquement compatible AVX2.  
> â— Malheureusement, **certaines cartes mÃ¨res dÃ©sactivent cette instruction** au niveau BIOS, ce qui empÃªche lâ€™exÃ©cution de TensorFlow, nÃ©cessaire pour le LSTM et BERT.

ğŸ› ï¸ Solution : **dÃ©ploiement sur Google Cloud Run**, Ã  lâ€™adresse suivante :  
ğŸ”— [https://sentiment-api-service-7772256003.europe-west1.run.app/](https://sentiment-api-service-7772256003.europe-west1.run.app/)

ğŸ“¸ *[InsÃ©rer capture console Google Cloud / endpoint]*

---

## ğŸ“Š Monitoring maison en production

L'API embarque une **logique dâ€™alerte interne** en cas de dÃ©rive.

ğŸ¯ **Comportement :**
- Si plus de **3 prÃ©dictions incorrectes** sont identifiÃ©es dans une **fenÃªtre de 5 minutes**, un **rapport dâ€™erreur** est gÃ©nÃ©rÃ© automatiquement.
- Ces erreurs peuvent Ãªtre loggÃ©es ou transmises via webhook selon la configuration future.

Cela permet de garder un **Å“il lÃ©ger mais rÃ©actif** sur les dÃ©rives en production, sans surcharger lâ€™infrastructure.

---

## ğŸ§  SchÃ©ma global du pipeline MLOps

      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚  DonnÃ©es   â”‚
      â”‚ (tweets)   â”‚
      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    PrÃ©traitement (regex, tokenisation, lemmatisation, stopwords)
           â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚  EntraÃ®nement ML   â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
    Log via MLFlow + artefacts MinIO
           â”‚
 SÃ©lection du meilleur modÃ¨le "avancÃ©" (hors BERT) selon prÃ©cision
           â”‚
 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚    API FastAPI     â”‚
 â”‚    + Streamlit     â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
 DÃ©ploiement sur Google Cloud Run
           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Monitoring lÃ©ger maisonâ”‚
â”‚ (alertes sur mauvaises â”‚
â”‚       prÃ©dictions)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## âœ¨ Conclusion

Ce projet a permis dâ€™explorer en profondeur les enjeux de classification de sentiments et les **limites des approches standards face Ã  la richesse du langage naturel**, en particulier sur Twitter.  
Il a aussi dÃ©montrÃ© lâ€™intÃ©rÃªt dâ€™un **pipeline MLOps souverain**, reproductible et automatisÃ©.  

> âœ… En alliant des modÃ¨les puissants, des outils robustes comme MLFlow et FastAPI, et un dÃ©ploiement maÃ®trisÃ©, on pose les bases dâ€™un produit de NLP industrialisable.

---

ğŸ’¬ Merci pour votre lecture !  
Pour tester lâ€™API : [https://sentiment-api-service-7772256003.europe-west1.run.app/](https://sentiment-api-service-7772256003.europe-west1.run.app/)


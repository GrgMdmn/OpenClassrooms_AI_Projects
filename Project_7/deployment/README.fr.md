# DÃ©ploiement de lâ€™API â€“ Projet Air Paradis

ğŸ“˜ Cette documentation est aussi disponible en [anglais ğŸ‡¬ğŸ‡§](./README.md)

Ce dossier contient le code et la configuration nÃ©cessaires au dÃ©ploiement de lâ€™API de prÃ©diction de sentiment.

---

## ğŸ¯ Objectif

DÃ©ployer une API REST permettant de :

- PrÃ©dire le **sentiment dâ€™un tweet** (positif ou nÃ©gatif) Ã  partir dâ€™un modÃ¨le LSTM entraÃ®nÃ© sur des embeddings (Word2Vec ou GloVe),
- Signaler les erreurs de prÃ©diction.

Lâ€™API utilise le **meilleur modÃ¨le enregistrÃ©** dans MLflow et le sert via **FastAPI**.

---

## ğŸ“¦ Architecture globale

SchÃ©ma :

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚    Utilisateur final (UI)    â”‚
    â”‚    (interface Streamlit)     â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
      [Appel HTTP vers /predict]
                 â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚         API FastAPI      â”‚
    â”‚  (serveur lancÃ© via      â”‚
    â”‚   Uvicorn)               â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
    Chargement du modÃ¨le (MLflow)
                 â”‚
     PrÃ©traitement du tweet
                 â”‚
        PrÃ©diction (infÃ©rence)
                 â”‚
     RÃ©ponse JSON avec le sentiment
```

---

## ğŸ§ª Fonctionnement de lâ€™API

1. **Chargement du modÃ¨le**
   - Le meilleur modÃ¨le est enregistrÃ© dans MLflow sous le nom `SentimentAnalysisLSTM`, avec le stage `Production`.
   - Lâ€™API le charge au dÃ©marrage via lâ€™URI :

     ```
     models:/SentimentAnalysisLSTM/Production
     ```

2. **PrÃ©traitement du texte**
   - Nettoyage, tokenisation, lemmatisation, puis conversion en vecteurs dâ€™embedding.

3. **PrÃ©diction**
   - Le modÃ¨le LSTM prÃ©dit le sentiment.
   - Le rÃ©sultat (`positive` ou `negative`) est retournÃ© en JSON.

4. **Interface utilisateur (optionnelle)**
   - Une interface Streamlit permet une interaction visuelle avec lâ€™API.

---

## ğŸ³ DÃ©ploiement via Docker

Un `Dockerfile` est fourni pour simplifier le dÃ©ploiement sur tout hÃ´te compatible Docker (NAS, cloud, etc.).

Lâ€™image Docker est poussÃ©e sur DockerHub Ã  chaque version validÃ©e (voir CI/CD plus bas).

Par souci de **souverainetÃ© des donnÃ©es**, le dÃ©ploiement est prÃ©fÃ©rÃ© sur un **NAS Ã©quipÃ© dâ€™un processeur Intel N100** (peu Ã©nergivore et suffisant pour lâ€™infÃ©rence LSTM).

Le redÃ©ploiement peut Ãªtre automatisÃ© via :
- une tÃ¢che `cron` simple, ou
- un conteneur **Watchtower** (dans docker-compose ou kubernetes).

**Commande pour test local :**

```bash
docker build -t sentiment-api .
docker run --rm --env-file ../../.env -p 8000:8000 -p 8080:8080 sentiment-api
```

En production, les variables dâ€™environnement doivent Ãªtre dÃ©finies dans le `docker-compose.yml` ou via un gestionnaire de secrets.

---

## ğŸ›  ProblÃ¨mes AVX2 / DÃ©ploiement cloud

**Mise Ã  jour :** au dÃ©part, le NAS ne supportait pas les instructions AVX2 nÃ©cessaires Ã  TensorFlow.  
En rÃ©alitÃ©, les CPU N100 les prennent en charge, mais certains fabricants dÃ©sactivent cette option dans le BIOS.

En attendant un accÃ¨s physique au NAS, nous avons optÃ© pour un dÃ©ploiement sur **Google Cloud**.  
ProblÃ¨me : un seul port peut Ãªtre exposÃ© publiquement sur ces services.

Deux solutions possibles :
- SÃ©parer le backend (FastAPI) et le frontend (Streamlit) en deux conteneurs,
- Utiliser un **reverse proxy** (ex. : nginx) pour rediriger les ports.

â¡ï¸ Nous avons choisi la **deuxiÃ¨me solution**, pour garder une **seule image Docker**.

**Mise Ã  jour 2 :** AVX2 a Ã©tÃ© activÃ© via le BIOS. Le dÃ©ploiement est donc opÃ©rationnel **Ã  la fois en local (NAS)** et **sur le cloud**, avec dÃ©ploiement automatique pour le NAS (voir section suivante).

---

## ğŸ” CI/CD â€“ GitHub Actions

Un pipeline est dÃ©fini dans `.github/workflows/` pour :

- Lancer les tests unitaires Ã  chaque `push`,
- VÃ©rifier la stabilitÃ© de lâ€™API avant dÃ©ploiement (NAS ou cloud),
- Construire et pousser lâ€™image Docker sur DockerHub.

Les tests sont situÃ©s dans :

```
deployment/api/tests/
```

Le redÃ©ploiement automatique sur le NAS est gÃ©rÃ© via **Watchtower**, qui surveille les mises Ã  jour de lâ€™image Docker (fonctionne comme un `cron`, avec logs).

---

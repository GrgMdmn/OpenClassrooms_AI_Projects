# DÃ©ploiement de l'API - Projet Air Paradis

Ce dossier contient le code et la configuration nÃ©cessaires pour dÃ©ployer l'API de prÃ©diction de sentiments.

## ğŸ¯ Objectif

DÃ©ployer une API REST qui permet de:
- prÃ©dire le sentiment dâ€™un tweet (positif ou nÃ©gatif) en sâ€™appuyant sur un modÃ¨le LSTM entraÃ®nÃ© Ã  partir dâ€™embeddings (Word2Vec ou GloVe).
- reporter les erreurs de prÃ©dictions


Lâ€™API utilise le modÃ¨le le plus performant, enregistrÃ© sur MLflow, et le met Ã  disposition via FastAPI.

---

## ğŸ“¦ Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Utilisateur final (UI)      â”‚
â”‚  (interface Streamlit)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
  [Appel HTTP Ã  /predict]
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       API FastAPI        â”‚
â”‚  (serveur lancÃ© via      â”‚
â”‚   Uvicorn)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
Chargement du modÃ¨le depuis MLflow
             â”‚
   PrÃ©traitement du tweet
             â”‚
     PrÃ©diction (infÃ©rence)
             â”‚
    Retour du sentiment (JSON)
```

---

## ğŸ§ª Fonctionnement de lâ€™API

1. **Chargement du modÃ¨le**
   - Le modÃ¨le le plus performant est enregistrÃ© dans MLflow sous un nom fixe (`SentimentAnalysisLSTM`) et une Ã©tape (stage) `Production`.
   - Lâ€™API rÃ©cupÃ¨re ce modÃ¨le au dÃ©marrage grÃ¢ce Ã  une URI stable :  
     ```
     models:/SentimentAnalysisLSTM/Production
     ```

2. **PrÃ©traitement du texte**
   - Le texte envoyÃ© par lâ€™utilisateur est nettoyÃ©, tokenisÃ©, lemmatisÃ© et transformÃ© en vecteurs (embeddings).

3. **PrÃ©diction**
   - Le modÃ¨le LSTM (chargÃ© depuis MLflow) effectue lâ€™infÃ©rence.
   - Le rÃ©sultat (`positif` ou `nÃ©gatif`) est renvoyÃ© en rÃ©ponse JSON.

4. **Interface utilisateur (optionnelle)**
   - Une interface Streamlit permet dâ€™interagir avec lâ€™API de maniÃ¨re visuelle.

---

## ğŸ³ DÃ©ploiement avec Docker

Un `Dockerfile` est fourni pour faciliter le dÃ©ploiement de lâ€™API sur nâ€™importe quel hÃ´te compatible Docker (NAS, cloud, etc.).

Ce docker devra Ãªtre dÃ©ploignÃ© sur DockerHub Ã  chaque versionning validÃ© (voir section CI/CD ci-dessous)

Dans un souci de souverainetÃ© des donnÃ©es, le dÃ©ploiement sera prÃ©fÃ©rentiellement dÃ©ployÃ© sur un NAS Ã©quippÃ© d'un processeur Intel N100 (peu Ã©nergivore, mais probablement suffisant pour un calcul d'infÃ©rence LSTM).

Pour le lancement du docker en local (dÃ©veloppement), il sera important de donner en entrÃ©e le fichier `.env` contenant les variables d'environnement ainsi que qu'ouvrir les ports de FastAPI et Streamlit pour pouvoir tester l'application.

`docker build -t sentiment-api`
`docker run --env-file ../../.env -p 8000:8000 -p 8501:8501 sentiment-api`

Pour un dÃ©ploiement sur un cloud personnel ou grand public (avec docker-compose, kubernetes), il sera prÃ©fÃ©rable de renseigner les variables d'environnement nÃ©cessaires dans `docker-compose.yml` ou dans les secrets.

Dans notre cas, il a Ã©tÃ© dÃ©cidÃ© d'utiliser Google Cloud. Une problÃ©matique classique se pose ici pour nous : on ne peut exposer  plusieurs ports (contrairement Ã  l'instruction ci-dessus) sur un service cloud.
2 options sont donc possibles:
- SÃ©parer le service en deux docker (un pour le backend fastAPI et un pour le frontend streamlit)
- Configurer un reverse proxy de type nginx pour qui aura pour but de rediriger les requÃªtes sur diffÃ©rents ports internes

Nous avons dÃ©cidÃ© de retenir la deuxiÃ¨me solution afin de pouvoir installer l'API Ã  partir d'un seul docker.

---

## ğŸ” IntÃ©gration continue / DÃ©ploiement Continu

Un pipeline GitHub Actions (CI/CD) est prÃ©vu pour :
- **Lancer automatiquement les tests unitaires** Ã  chaque push sur le dÃ©pÃ´t GitHub.
- **Garantir la stabilitÃ© de lâ€™API** avant tout dÃ©ploiement (NAS ou cloud).
- **Mettre Ã  jour le Dockerfile** et le pousser sur **DockerHub**.

Les tests unitaires seront dÃ©finis dans `./deployment/api/tests/`

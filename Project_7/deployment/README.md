# DÃ©ploiement de l'API - Projet Air Paradis

Ce dossier contient le code et la configuration nÃ©cessaires pour dÃ©ployer l'API de prÃ©diction de sentiments.

## ğŸ¯ Objectif

DÃ©ployer une API REST qui permet de:
- prÃ©dire le sentiment dâ€™un tweet (positif ou nÃ©gatif) en sâ€™appuyant sur un modÃ¨le LSTM entraÃ®nÃ© Ã  partir dâ€™embeddings (Word2Vec ou GloVe).
- reporter les erreurs de prÃ©dictions


Lâ€™API utilise le modÃ¨le le plus performant, enregistrÃ© sur MLflow, et le met Ã  disposition via FastAPI.

---

## ğŸ“¦ Architecture Globale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Utilisateur final (UI)      â”‚
â”‚  (interface Streamlit)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
  [Appel HTTP Ã  /predict]
             â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       API FastAPI        â”‚
â”‚  (serveur lancÃ© via      â”‚
â”‚   Uvicorn)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
Chargement du modÃ¨le depuis MLflow
             â”‚
   PrÃ©traitement du tweet
             â”‚
     PrÃ©diction (infÃ©rence)
             â”‚
    Retour du sentiment (JSON)
```

---

## ğŸ§ª Fonctionnement de lâ€™API

1. **Chargement du modÃ¨le**
   - Le modÃ¨le le plus performant est enregistrÃ© dans MLflow sous un nom fixe (`SentimentAnalysisLSTM`) et une Ã©tape (stage) `Production`.
   - Lâ€™API rÃ©cupÃ¨re ce modÃ¨le au dÃ©marrage grÃ¢ce Ã  une URI stable :  
     ```
     models:/SentimentAnalysisLSTM/Production
     ```

2. **PrÃ©traitement du texte**
   - Le texte envoyÃ© par lâ€™utilisateur est nettoyÃ©, tokenisÃ©, lemmatisÃ© et transformÃ© en vecteurs (embeddings).

3. **PrÃ©diction**
   - Le modÃ¨le LSTM (chargÃ© depuis MLflow) effectue lâ€™infÃ©rence.
   - Le rÃ©sultat (`positif` ou `nÃ©gatif`) est renvoyÃ© en rÃ©ponse JSON.

4. **Interface utilisateur (optionnelle)**
   - Une interface Streamlit permet dâ€™interagir avec lâ€™API de maniÃ¨re visuelle.

---

## ğŸ³ DÃ©ploiement avec Docker

Un `Dockerfile` est fourni pour faciliter le dÃ©ploiement de lâ€™API sur nâ€™importe quel hÃ´te compatible Docker (NAS, cloud, etc.).

Dans un souci de souverainetÃ© des donnÃ©es, le dÃ©ploiement sera prÃ©fÃ©rentiellement dÃ©ployÃ© sur un NAS Ã©quippÃ© d'un processeur Intel N100 (peu Ã©nergivore, mais probablement suffisant pour un calcul d'infÃ©rence LSTM).
Un dÃ©ploiement sur cloud grand public pourra Ã©ventuellement Ãªtre effectuÃ© en fonction des demandes du jury du projet.

Exemple de build et run :
```bash
docker build -t air-paradis-api .
docker run -p 8000:8000 --env-file ../.env air-paradis-api

---

## ğŸ” IntÃ©gration continue

Un pipeline GitHub Actions (CI/CD) est prÃ©vu pour :
- **Lancer automatiquement les tests unitaires** Ã  chaque push sur le dÃ©pÃ´t GitHub.
- **Garantir la stabilitÃ© de lâ€™API** avant tout dÃ©ploiement (NAS ou cloud).

Les tests seront dÃ©finis dans `test_api.py`, avec des cas simples de requÃªtes POST sur `/predict`.

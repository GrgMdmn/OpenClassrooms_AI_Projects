# Projet de Scoring Cr√©dit - Pr√™t √† d√©penser

## üìã Contexte du projet

Ce projet a √©t√© r√©alis√© pour **"Pr√™t √† d√©penser"**, une soci√©t√© financi√®re sp√©cialis√©e dans l'octroi de cr√©dits √† la consommation. L'entreprise souhaite mettre en place un **outil de scoring cr√©dit** permettant d'√©valuer la probabilit√© qu'un client rembourse son pr√™t et ainsi automatiser le processus de d√©cision d'octroi de cr√©dit.

## üéØ Objectifs

Les objectifs principaux du projet sont :

1. **D√©velopper un mod√®le de scoring** : Cr√©er un mod√®le pr√©dictif robuste capable d'√©valuer le risque de d√©faut de paiement
2. **Optimiser le co√ªt m√©tier** : Minimiser les pertes financi√®res en tenant compte du co√ªt r√©el des faux positifs et faux n√©gatifs
3. **Assurer l'interpr√©tabilit√©** : Fournir des explications claires sur les d√©cisions du mod√®le pour les charg√©s de relation client
4. **G√©rer le d√©s√©quilibre des classes** : Traiter efficacement les donn√©es d√©s√©quilibr√©es caract√©ristiques du domaine du cr√©dit

## üìä Donn√©es

Les donn√©es proviennent du concours Kaggle **"Home Credit Default Risk"** et comprennent :
- L'historique de cr√©dit des clients
- Les demandes de pr√™t pr√©c√©dentes
- Les informations sur les cartes de cr√©dit
- Les donn√©es de paiement par acomptes
- Les soldes POS (Point of Sale) et cash

**‚ö†Ô∏è Note importante** : Les fichiers de donn√©es bruts ne sont pas inclus dans ce d√©p√¥t en raison de leur taille importante. Ils sont t√©l√©chargeables √† l'adresse suivante :
- **URL** : https://www.kaggle.com/competitions/home-credit-default-risk/data

Les fichiers n√©cessaires incluent :
- `application_train.csv` / `application_test.csv`
- `bureau.csv`
- `previous_application.csv`
- `credit_card_balance.csv`
- `installments_payments.csv`
- `POS_CASH_balance.csv`

## üìÅ Structure du projet

```
‚îú‚îÄ‚îÄ P4_01_notebook_analyse_exploratoire_feature_engineering.ipynb
‚îú‚îÄ‚îÄ P4_02_notebook_modelisation.ipynb
‚îú‚îÄ‚îÄ P4_03_presentation.pptx
‚îú‚îÄ‚îÄ explication_client_0.html
‚îî‚îÄ‚îÄ explication_client_2.html
```

### 1. `P4_01_notebook_analyse_exploratoire_feature_engineering.ipynb`

**Notebook d'Analyse Exploratoire des Donn√©es (EDA) et Feature Engineering**

Ce notebook contient l'ensemble de la phase de pr√©paration des donn√©es :

**Exploration des donn√©es** :
- Chargement et analyse des diff√©rents fichiers CSV
- √âtude de la distribution de la variable cible (d√©s√©quilibre des classes)
- Analyse des valeurs manquantes et des valeurs atypiques
- √âtude des corr√©lations entre variables et avec la cible

**Enrichissement des donn√©es** :
- Fusion intelligente des diff√©rentes sources de donn√©es (bureau, previous_application, etc.)
- Agr√©gation d'informations provenant de multiples tables
- Cr√©ation de variables m√©tier pertinentes (ratios, moyennes, statistiques)

**Feature Engineering** :
- Cr√©ation de nouvelles caract√©ristiques bas√©es sur des ratios m√©tiers
- Encodage des variables cat√©gorielles
- Imputation des valeurs manquantes
- Normalisation et standardisation des variables
- Pr√©paration sp√©cifique pour les mod√®les tol√©rant les valeurs manquantes (LightGBM)

### 2. `P4_02_notebook_modelisation.ipynb`

**Notebook de Mod√©lisation, Optimisation et Interpr√©tation**

Ce notebook pr√©sente l'int√©gralit√© du processus de mod√©lisation :

**Mod√©lisation de base** :
- R√©gression logistique (baseline)
- Random Forest
- √âvaluation avec m√©triques standards (AUC-ROC, pr√©cision, recall)

**Mod√©lisation avanc√©e** :
- Entra√Ænement de mod√®les gradient boosting : XGBoost, LightGBM, CatBoost
- Gestion du d√©s√©quilibre des classes (class_weight, scale_pos_weight)
- Optimisation des hyperparam√®tres avec GridSearchCV

**Optimisation m√©tier** :
- D√©finition d'un **score m√©tier** int√©grant le co√ªt des faux positifs et faux n√©gatifs
- D√©termination du **seuil de d√©cision optimal** pour minimiser les pertes financi√®res
- Analyse de la courbe co√ªt-seuil

**Interpr√©tabilit√©** :
- **Interpr√©tation globale** : Importance des variables avec SHAP (TreeExplainer)
- **Interpr√©tation locale** : Explication des pr√©dictions individuelles avec LIME
- Analyse de l'impact de chaque variable sur les d√©cisions

**Simplification du mod√®le** :
- S√©lection des variables les plus importantes
- R√©duction du nombre de features tout en maintenant les performances (AUC)

### 3. `P4_03_presentation.pptx`

**Pr√©sentation de Soutenance**

Cette pr√©sentation synth√©tise :
- Le contexte m√©tier et les enjeux du scoring cr√©dit
- La m√©thodologie de pr√©paration et d'enrichissement des donn√©es
- La comparaison des diff√©rents mod√®les test√©s
- Le choix du mod√®le final et son optimisation m√©tier
- L'approche d'interpr√©tabilit√© globale et locale (SHAP et LIME)
- Les recommandations et perspectives d'am√©lioration

### 4. `explication_client_0.html` et `explication_client_2.html`

**Rapports d'Interpr√©tation Locale des Pr√©dictions**

Ces rapports HTML interactifs illustrent des exemples concrets d'explications pour des clients individuels :
- Les pr√©dictions du mod√®le pour chaque client (probabilit√© de d√©faut)
- Les explications SHAP et/ou LIME d√©taillant pourquoi le mod√®le a pris telle d√©cision
- La contribution de chaque variable √† la pr√©diction finale pour ce client sp√©cifique
- Des visualisations permettant aux charg√©s de client√®le de comprendre et justifier les d√©cisions
- Des exemples de cas d'acceptation et de refus avec leurs justifications

Ces fichiers servent de d√©monstration du syst√®me d'interpr√©tabilit√© locale qui pourrait √™tre d√©ploy√© en production pour expliquer chaque d√©cision de cr√©dit.

## üõ†Ô∏è Technologies utilis√©es

- **Python** : D√©veloppement et analyse
  - pandas, numpy : manipulation de donn√©es
  - scikit-learn : mod√®les de base, preprocessing, m√©triques
  - XGBoost, LightGBM, CatBoost : mod√®les de gradient boosting
  - SHAP : interpr√©tation globale des mod√®les
  - LIME : interpr√©tation locale des pr√©dictions
  - matplotlib, seaborn, plotly : visualisation
- **Jupyter Notebook** : d√©veloppement et documentation

## üìà M√©thodologie

1. **Exploration et compr√©hension** : Analyse approfondie des donn√©es multi-sources
2. **Feature Engineering** : Cr√©ation de variables m√©tier pertinentes par agr√©gation et transformation
3. **Mod√©lisation** : Test de plusieurs algorithmes avec gestion du d√©s√©quilibre
4. **Optimisation m√©tier** : D√©finition et optimisation d'un score m√©tier int√©grant les co√ªts r√©els
5. **Interpr√©tabilit√©** : Mise en place d'outils d'explication globale (SHAP) et locale (LIME)
6. **Validation** : √âvaluation sur donn√©es test et v√©rification de la g√©n√©ralisation

## üéØ R√©sultats attendus

- ‚úÖ Dataset enrichi et pr√©trait√© avec nouvelles features m√©tier
- ‚úÖ Mod√®le de scoring optimis√© selon un crit√®re m√©tier (minimisation des co√ªts)
- ‚úÖ Seuil de d√©cision optimal d√©termin√©
- ‚úÖ Rapports d'interpr√©tabilit√© globale et locale
- ‚úÖ Documentation compl√®te pour les utilisateurs finaux

## üí° Points cl√©s du projet

### Gestion du d√©s√©quilibre des classes
Le dataset pr√©sente un fort d√©s√©quilibre entre les bons et mauvais payeurs. Plusieurs techniques ont √©t√© mises en ≈ìuvre :
- Utilisation de param√®tres `class_weight` et `scale_pos_weight`
- Optimisation bas√©e sur des m√©triques appropri√©es (AUC-ROC, recall, score m√©tier)
- Ajustement du seuil de d√©cision post-mod√©lisation

### Score m√©tier personnalis√©
Plut√¥t que de se fier uniquement aux m√©triques classiques, un **score m√©tier** a √©t√© d√©fini prenant en compte :
- Le co√ªt d'un faux positif (refus √† tort d'un bon client ‚Üí perte d'opportunit√©)
- Le co√ªt d'un faux n√©gatif (acceptation d'un mauvais payeur ‚Üí perte financi√®re importante)
- L'optimisation du seuil de d√©cision pour minimiser le co√ªt total

### Interpr√©tabilit√©
Deux niveaux d'interpr√©tation ont √©t√© impl√©ment√©s :
- **Globale (SHAP)** : Quelles variables sont les plus importantes pour le mod√®le en g√©n√©ral ?
- **Locale (LIME)** : Pourquoi le mod√®le a-t-il pris cette d√©cision pour ce client sp√©cifique ?

Cette double approche permet aux charg√©s de relation client de comprendre et d'expliquer les d√©cisions aux demandeurs de cr√©dit.

## üéì Comp√©tences d√©velopp√©es

- Pr√©paration et enrichissement de donn√©es multi-sources complexes
- Feature engineering orient√© m√©tier dans le domaine financier
- Mod√©lisation avec gestion du d√©s√©quilibre des classes
- Optimisation bas√©e sur des crit√®res m√©tier (co√ªt/b√©n√©fice)
- Interpr√©tabilit√© des mod√®les de machine learning (SHAP, LIME)
- Communication des r√©sultats techniques √† des audiences m√©tier

## üë§ Auteur

**Gr√©goire Mureau**

---

*Ce projet illustre la d√©marche compl√®te de data science appliqu√©e au scoring cr√©dit : de la pr√©paration des donn√©es √† l'optimisation m√©tier, en passant par l'interpr√©tabilit√© des mod√®les.*
